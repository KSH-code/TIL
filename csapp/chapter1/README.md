# 컴퓨터 시스템
하드웨어와 시스템 소프트웨어로 구성되며, 함께 작동하여 응용프로그램을 실행한다.
## 시스템의 구현방법
시간에 따라 바뀔 수 있지만, 근본적인 방법은 바뀌지 않는다.

모든 컴퓨터 시스템들은 유사한 기능을 수행하는 유사한 하드웨어와 소프트웨어 컴포넌트를 가지고 있다.

우리는 컴포넌트들이 어떻게 동작하고 프로그램의 성능과 정확성에 어떤 영향을 주는지 알아보자.

[hello.c](hello.c) 를 실행하면 어떻게 시스템에서 실행되고, 출력되고, 종료될 때 까지의 수명주기를 추적한다.
# 1. 정보는 비트와 컨텍스트로 이루어진다.
hello.c 는 텍스트 파일이다.

소스 프로그램은 2진수의 연속이고, 바이트로 구성된다.

각 바이트는 텍스트 문자를 나타낸다. (ASCII 표준 사용)

아스키 문자들로만 이루어진 파일들을 *텍스트 파일* 이라고 부른다.

아니면 *바이너리 파일* 이라고 한다.

모든 시스템 내부의 정보와 데이터는 비트(binary number)들로 표시된다.
# 2. 프로그램은 다름 프로그램에 의해 다른 형태로 번역됨
hello 프로그램은 텍스트 파일이여서 사람이 이해할 수 있다.

hello.c 를 시스템에서 실행시키려면, 저급 *기계어 인스트럭션*들로 번역해야 된다.

이 인스트럭션들은 실행가능 *목적 프로그램*이라는 형태로 합쳐지고 바이너리 디스크 파일로 저장된다.

목적프로그램은 실행 가능 *목적 파일*로도 부른다.
# GCC 컴파일 시스템의 단계
1. 전처리 단계
    * 전처리기는 # 문자로 시작하는 디렉티브에 따라 수정한다. #include <stdio.h> 가 있다고 가정하면, stdio.h 헤더 파일을 직접 넣어준다.
    * 결과적으로는 .i 파일이 생성된다. (hello.i)
2. 컴파일 단계
    * 텍스트 파일 .i 를 .s 형태로 변역한다. .s 에는 *어셈블리어 프로그램*이 저장된다. (hello.s)
3. 어셈블리 단계
    * .s 를 기계어 인스트럭션으로 번역하고, 재배치가능 목적프로그램의 형태로 묶어서 .o 로 저장한다.
4. 링크 단계
    * printf 함수 즉 표준 라이브러리에 들어있는 함수를 호출해야 된다. printf 는 printf.o 에 저장돼있으며, hello.o 와 결합되어야 한다.
    * 이 작업을 링커프로그램이 하며, hello 파일은 실행가능 목적파일(즉 실행파일 .exe?)로 메모리에 적재되어 실행된다.
# 3. 컴파일 시스템이 어떻게 동작하는지 이해하는 것은 중요하다
`hello.c` 처럼 간단한 프로그램의 경우 컴파일 시스템이 정확하고 효율적인 기계어 코드를 만들어 줄 거라고 기대할 수 있다.

하지만 프로그래머들은 어떻게 컴파일이 되는지 알 필요가 있다.
* 프로그램 성능 최적화하기
    * if-else 가 switch 보다 빠를까?
    * while-loop 이 for-loop 보다 빠를까?
    * 합계를 지역변수에 저장하면 참조 형태로 넘겨받는 인자를 사용하는 것보다 왜 loop 이 더 빨리 실행될까?
* 링크 에러 이해하기
    * 정적변수와 전역변수의 차이는 무엇인가?
    * 각기 다른 파일에서 같은 이름의 전역변수를 정의한다면?
    * 정적 라이브러리와 동적 라이브러리의 차이점은?
* 보안 약점
    * 방어하는 방법을 배운다
# 4. 프로세서는 메모리에 저장된 인스트럭션을 읽고 해석한다
`hello.c` 소스 프로그램은 컴파일 시스템에 의해 실행 가능한 목적 파일로 디스크에 변환된다.
# 4.1 시스템의 하드웨어 조직
* Buses (Bus)
    * 시스템 내를 관통하는 전기적 배선군
    * 컴포넌트들 간에 바이트 정보 전송
    * 일반적으로 word
        * 32 비트 4 바이트
        * 64 비트 8 바이트
* I/O 장치
    * 입력
        * 키보드
        * 마우스
    * 출력
        * 디스플레이
        * 디스크 드라이브
    * 입출력 버스와 컨트롤러나 어댑터를 통해 연결
* 메인 메모리
    * 프로세서가 프로그램을 실행하는 동안 데이터와 프로그램을 모두 저장하는 임시 저장장치
    * 물리적 DRAM(Dynamic Random Access Memory)
    * 연속적인 바이트들의 배열
* 프로세서
    * 메인 메모리에 저장된 인스트럭션들을 해독
    * 중심에 워드 크기의 저장장치 (또는 레지스터) 인 PC(Program Counter) 가 있다.
    * PC 가 가르키는 곳의 인스트럭션을 반복적 실행
    * PC 의 다음 인스트럭션의 위치 업데이트
    * 순환
        * 메인 메모리
        * 레지스터 파일
        * 수식/논리 처리기(ALU)
    * 단순 작업
        * Load 메인 메모리에서 레지스터에 바이트 또는 워드를 덮어씌움
        * Store 레지스터에서 메인 메모리로 바이트 또는 워드를 이전 값을 덮어씌움
        * Operate 두 레지스터의 값을 ALU 로 복사 -> 두 개의 워드로 수식 연산 후 덮어씌움
        * Jump 인스트럭션 자신으로부터 워드 추출 PC 에 덮어씌움
# 4.2 hello 프로그램의 실행
* 쉘 프로그램은 자신의 인스트럭션 실행
* 사용자 명령 입력 대기
* 입력되면 문자를 레지스터에 읽어드림
* 메모리 저장
1. I/O 장치 ->  I/O bus 를 통해 -> I/O bridge -> System bus 를 통해 -> Bus interface -> Register file -> System bus 를 통해 -> I/O bridge -> Memory bus 를 통해 -> Main memory
2. Disk -> I/O bus 를 통해 -> I/O bridge -> Memory bus 를 통해 -> Main memory
3. Main memory -> Memory bus 를 통해 -> I/O bridge -> System bus 를 통해 -> Bus interface -> Register file -> Bus interface -> System bus 를 통해 -> I/O bridge -> I/O bus 를 통해 -> Display

.
1. 키보드 입력
2. 실행 파일 로드
3. 출력
# 5 캐시가 중요하다
정보를 한 곳에서 한 곳으로 이동하는 것은 많은 시간이 소모된다.

본래에 하드디스크에 존재하던 기계어 인스트럭션들을 메모리에 복사되고, 메모리에 있는 스트링은 디스플레이 장치로 복사된다.

이런 복사과정들이 "실제 작업"을 느리게 하는 오버헤드다.

물리학의 법칙 때문에 더 큰 저장장치들은 보다 작은 저장장치들보다 느린 속도를 가진다.

캐시 메모리라고 부르는 저장장치를 고안하여 프로세서가 단기간에 필요로 할 가능성이 높은 정보를 임시로 저장할 목적으로 사용한다.

* Main memory -> Memory bus 를 통해 -> I/O bridge -> System bus 를 통해 -> Bus interface -> Register file -> ALU -> Register file -> Cache memories <=> Bus interface
레지스터에 계속 접근하지 않고, 자주 사용하는 데이터는 Cache memory 에 저장되는거 같다.

프로세서가 액세스 할 경우
* L1 cache 는 L2 cache 보다 5배 정도 빠르다.
* L2 cache 는 메인 메모리 보다 5 ~ 10 배 빠르다.
하지만 수치는 정확하지 않고, 변할 가능성이 크므로 신뢰하지 말자.
L1, L2 cache 는 SRAM (Static Random Access Memory) 라는 하드웨어 기술을 이용해 구현한다.

새롭고 강력한 시스템은 심지어 3단계의 캐시를 갖는 경우도 있다.

L1, L2, L3

캐시 시스템의 이면에 깔려 있는 아이디어는 프로그램이 지엽적인 영역의 코드와 데이터를 액세스하는 경향인 지역성을 활용하여 시스템이 매우 크고 빠른 메모리 효과를 얻을 수 있다는 것이다.

캐시 메모리를 활용하면 성능이 많이 개선된다.
# 6 저장장치들은 계층구조를 이룬다.
캐시메모리를 프로세서와 좀 더 크고 느린 (메인 메모리) 사이에 끼워 넣는 개념은 일반적인 아이디어로 판명 되었다.
* L0: Register
* L1: SRAM
* L2: SRAM
* L3: SRAM
* L4: DRAM (Main memory)
* L5: Local secondary storage (local disk)
* L6: Remote secondary storage (web server, distributed file systems)

가격은 0 -> 6 으로 갈수록 비싸지고, 용량은 커진다.

메모리 계층구조의 주요 아이디어는 한 레벨의 저장장치가 다음 하위레벨 저장장치의 캐시 역할을 한다는 것이다.

예를 들어서, L4 에 많이 사용하는 데이터는 L3 에 저장할 수 있다는 것이다.

그러면 L4 의 캐시 메모리는 L3 이다.
# 7 운영체제는 하드웨어를 관리한다.
hello 예제를 보면 쉘 프로그램이 로드하고,
* 실행할 때
* 출력할 때
프로그램이 직접 하드웨어를 액세스 하지 않았다.

OS 가 제공하는 서비스를 이용한다.(system call)

운영체제는 두 가지 주요 목적을 가지고 있다.
1. 제멋대로 동작하는 응용프로그램들이 하드웨어를 잘못 사용하는 것을 막기 위해
2. 응용프로그램들이 단순하고 균일한 메커니즘을 사용하여 복잡하고 매우 다른 저수준 하드웨어 장치들을 조작할 수 있도록 하기 위해
```
        (Application programs) S/W

                (OS) S/W

(Processor | Main memory | I/O devices) H/W
```
추상화 한 형태다.

Application 은 하드웨어를 사용할 때, system call 을 이용한다.
# 7.1 프로세스
운영체제는 우리를 한 개의 프로그램만 실행되는 것 같은 착각에 빠지도록 한다.

프로그램이 프로세서, 메인 메모리, 입출력장치를 모두 독차지 하고 있는 것처럼 보인다.

프로세서는 프로그램 내의 인스트럭션들을 다른 방해 없이 순차적으로 실행하는 것처럼 보인다.

프로그램의 코드와 데이터가 시스템 메모리의 유일한 객체인 것처럼 보인다.

전산학에서 중요한 프로세스라고 하는 개념에 의해서 만들어졌다.

프로세스는 실행 중인 프로그램에 대한 운영체제의 추상화다.

다수의 프로세스는 동일한 시스템에서 동시에 실행될 수 있으며, 각 프로세스는 하드웨어를 배타적으로 사용하는 것처럼 누낀다.

동시에 라는 말은 한 프로세스의 인스트럭션들이 다른 프로세스의 인스트럭션들과 섞인다는 것을 의미한다.

운영체제는 문맥 전환 이라는 방법을 사용해서 교차실행을 수행한다.

운영체제는 프로세스가 실행하는 데 필요한 모든 상태정보의 변화를 추적한다.

컨텍스트라고 부르는 상태정보는 PC, 레지스터 파일, 메인 메모리의 현재 값을 포함하고 있다.

운영체제는 현재 프로세스에서 다른 프로세스로 제어를 옮기려고 할 때 현재 프로세스의 컨텍스트를 저장하고 넘긴다.

hello 프로그램을 실행하라는 명령을 받으면, 쉘은 system call 이라는 특수 함수를 호출해 운영체제로 제어권을 넘긴다.

운영체제는 쉘으 context 를 저장 -> hello 프로세스 실행 -> 종료 -> 쉘 프로세스 context 복구 -> 운영체제로 제어권 넘김

하나의 프로세스에서 다른 프로세스로의 전환은 운영체제 커널에 의해 관리됨

정리

1. 프로그램은 여러개가 동시에 실행이 된다.
2. 하지만 실제로 동시처리는 되지 않는다.
3. context = PC, 레지스터 파일, 메인 메모리 값 포함
4. 운영체제 <=> 프로세스 일 때, context 저장 및 복구
5. 운영체제 커널이 관리함
6. PC = Program Counter (다음 인스트럭션 실행 위치 저장)
# 7.2 쓰레드
프로세스가 한 개의 제어흐름을 갖는 것으로 생각할 수 있지만,

프로세스는 쓰레드 라는 다수의 실행 유닛으로 구성되어 있다.

각각의 쓰레드는 프로세스의 컨텍스트에서 실행되며 동일한 코드와 전역 데이터를 공유한다. (당연하다 ㅋ)

쓰레드는 프로그래밍 모델로서 중요성이 점점 커진다.

다수의 프로세스보다 데이터 공유가 더 쉽고 쓰레드가 더 효율적이라는 것이다.
# 7.3 가상메모리
가상메모리는 각 프로세스들이 메인 메모리 전체를 독점한다는 환상을 제공하는 추상화다.

리눅스에서, 주소공간의 최상위 영역은 모든 프로세스들이 공통으로 사용하는 운영체제의 코드와 데이터를 위한 공간이다.

주소공간의 하위 영역은 사용자 프로세스의 코드와 데이터를 저장한다.

```
Kernel virtual memory
User stack
```
&updownarrow;
```
Memory-mapped region for shared libraries(printf function)
```
&uparrow;
```
Run-time heap(created by malloc)
Read/write data             Loaded from the
Read-only code and data     hello executable file
0 (Program start)
```
아래에서 부터 위로 올라가는 설명이다.
* *프로그램 코드와 데이터* 코드는 모든 프로세스들이 같은 고정 주소에서 시작한다.

    C 전역변수에 대응되는 데이터 위치들이 따라온다.

    코드와 데이터 영역은 실행가능 목적파일인 hello 로 부터 직접 초기화 된다.
* *Heap* 코드와 데이터 영역 다음으로 런타임 힙이 따라온다.

    크기가 고정되어 있는 코드, 데이터 영역과 달리, 힙은 프로세스가 실행되면서 C 표준함수인 malloc이나 free를 호출하면서 런타임에 동적으로 그 크기가 늘엇다 줄었다 한다.
* *공유 라이브러리* 주소공간의 중간 부근에 C 표준 라이브러리나 수학 라이브러리와 같은 공유 라이브러리의 코드와 데이터를 저장하는 영역이 있다.
* *스택* 사용자 가상 메모리 공간의 맨 위에 컴파일러가 함수 호출을 구현하기 위해 사용자 스택이 위치한다.

    힙과 마찬가지로 프로그램이 실행 되는 동안 동적으로 변한다.

    함수를 호출할 때, 커지고

    반환될 때, 줄어난다.
* *커널 가상메모리* 주소공간의 맨 윗부분은 커널을 위해 예약 됨

    응용프로그램은 접근 불가!

    접근하려면 커널을 호출 해야됨
프로세스의 가상메모리의 내용을 디스크에 저장하고 메인 메모리를 디스크의 캐시로 사용하는 것이 가상메모리의 기본적인 아이디어다.
# 7.4 파일
파일은 바이트들의 연속이다.

디스크, 키보드, 디스플레이, 네트워크까지 포함하는 모든 입출력장치는 파일로 모델링한다.

시스템의 모든 입출력은 유닉스 I/O 라는 system call 을 이용해 파일을 읽고 쓰는 형태로 이뤄짐

고상한 파일 개념은 매우 강력한 것이어서

응용 프로그램에 시스템에 들어 잇는 다양한 입출력장치들의 통일된 관점 제공

ex ) 디스크 파일의 내요을 조작 하는 응용프로그래머는 특정 디스크를 다루는 기술을 몰라도 된다.
# 8 시스템은 네트워크를 사용해 다른 시스템과 통신함
네트워크는 입출력 장치로 볼 수 있따.

메인 메모리 -> 네트워크 어댑터

일련의 바이트 복사가 일어날 때, 데이터는 로컬디스크 드라이브 대신에 네트워크를 통해서 다른 컴퓨터로 이동한다.

마찬가지로 네트워크를 통해 들어온 데이터 -> 메인 메모리 복사 가능
# 9 중요한 주제들
스킵
# 9.1 Amdahl 의 법칙
성능 개선의 효율성 계산 방법
* 전체 시스템 성능에 대한 효과는 그 부분이 얼마나 중요한가
* 이 부분이 얼마나 빨라졌나

어떤 응용을 실행하는데 걸리는 시간 To

전체 시스템의 어떤 부분이 a 비율 만큼 시간 소모

성능을 k 배 개선

원래는 a * To 만큼 시간 요구

개선 후 : a * To / k

* Tn = (1 - a) * To + (a * To) / k
* = To * [(1 - a) + a / k]
* 개선된 속도 (S) = 1 / (1 - a) + a / k
## 연습문제 1
* 25 / 20 * 100
* 25 / t = 1.67
    * t = 15
    * 1500 / 5 = 300
## 연습문제 2
* 4 = 1 / (0.1 + 0.9 / k)
    * 0.4 + 3.6 / k = 1
    * 0.6 = 3.6 / k
    * k = 6
# 9.2 동시성과 병렬성
* 컴퓨터가 더 많은 일을 해내고, 더 빨리 실행되기를 원함
* 이들 요구 모두 프로세서가 한번에 더 많은 일을 하면 개선됨
* 동시성이라는 용어는 다수의 동시에 벌어지는 일을 갖는 시스템에 관한 일반적인 개념
    * 밥을 먹으면서 게임을 한다.
* 병렬성이라는 용어는 동시성을 사용해서 시스템을 보다 빠르게 동작하도록 하는 것을 말함
    * 밥을 먹으면서 게임을 한다. (빠르게 동작한다.)
* 병렬성은 컴퓨터 시스템의 다양한 수준의 추상화에서 활용 가능
## 쓰레드 수준 동시성
프로세스 추상화 개념을 이용하면 프로그램이 동시에 실행되는 시스템을 생각해볼 수 있다.
* 쓰레드를 이용하면 한 개의 프로세스에서 다수의 제어흐름을 가질 수 있다.
* time-sharing 기법의 출현으로 동시 실행에 대한 지원이 컴퓨터 시스템에 나타남
* time limit 를 해놓고 빠르게 변경 (동시에 실행하는 느낌을 느낄 수 있다. (운영체제에서 함))
* 하나의 프로세서만 있으면 *단일 프로세서 시스템*
* 여러개의 프로세서를 하나의 커널이 제어하면 *멀티 프로세서 시스템*
* 멀티코어 프로세서는 여러 개의 CPU 를 하나의 집적화된 칩에 내장한다.
* 프로세서 칩은 별도의 캐시를 가지고, 코어는 메인 메모리 인터페이스뿐만 아니라 상위 수준 캐시를 공유한다. (인텔 i7 프로세서의 예다.)
* 산업체 전문가들은 한 개의 칩에 10 ~ 수백 개의 코어를 넣는것이 가능하다고 예측
* 멀티쓰레딩
    * 하이퍼쓰레딩은 하나의 CPU 가 여러 개의 제어 흐름을 실행하는 기술
    * 프로그램 카운터나 레지스터 파일 같은 여러개의 동일한 CPU 하드웨어를 가지고 있는 반면, 부동소수 연산기와 같은 다른 부분들은 한 개의 하드웨어만 가지고 잇는 구조와 관련됨
* 하이퍼쓰레드 프로세서
    * 매 사이클마다 실행할 쓰레드를 결정
    * 예
        * 기다리는중인 쓰레드가 있으면
        * 다른 쓰레드를 실행
* 멀티프로세싱
    * 다수의 태스크를 실행할 때, 동시성을 시뮬레이션할 필요를 줄여준다.
    * 한 개의 응용프로그램을 빠르게 실행할 수 있지만, 프로그램이 병렬로 효율적으로 실행할 수 있는 멀티쓰레드의 형태로 표현되었을 때에만 가능하다.
### 인스트럭션 수준 병렬성
* 최근의 프로세서등른 훨신 낮은 수준에서의 추상화로 여러 개의 인스터럭션을 한 번에 실행한다.
* 이러한 특성을 인스터럭션 수준 병렬성이라고 한다.
* **여기서 잠깐** *병렬성* 이란?
    * 병렬성: 동시성을 사용해서 시스템을 보다 빠르게 동작하는 것을 말할 때 사용
        * **여기서 잠깐** *동시성* 이란?
            * 다수의 동시에 벌어지는 일을 갖는 시스템에 관한 일반적인 개념을 말할 때 사용
    * 동시에 여러가지 일을 갖는 시스템은 동시성
    * 동시성을 사용해 빠르게 동작하게 하면 병렬성
* 인스트럭션들은 시작부터 종료까지 훨씬 긴 시간이 필요하지만, 프로세서는 여러 가지 교묘한 기법을 이용해 한 번에 100개의 인스트럭션까지 처리가 가능하다.
* *파이프라이닝*: 여러 단계로 나누고 단계를 하나씩 실행하는것 (나중에 나온다.)
* *파이프라이닝*에서는 인스트럭션을 실행하기 위해 요구되는 일들을 여러 단계로 나눈다.
* 각 단계는 병렬로 동작할 수 있고, 서로 다른 부분을 이용할 수 있다.
* 사이클당 한 개 이상의 인스트럭션을 실행할 수 있는 프로세서를 *슈퍼스케일러*라고 한다.
    * 대부분의 최근 프로세서들은 다 지원함.
### 싱글 인스트럭션, 다중 데이터 병렬셩(SIMD)
많은 프로세서들은 최하위 수준에서 싱글 인스트럭션, 다중 데이터, 즉 SIMD 병렬성이라는 모드로 한 개의 인스트럭션이 병렬로 다수의 연산을 수행할 수 잇는 특수 하드웨어를 가지고 있다.
* SIMD 인스트럭션들은 대개 영상, 소리, 동영상 데이터 처리를 위한 으용프로그램의 속도를 개선하기 위해 제공
* 일부 컴파일러들이 자동으로 C 프로그램에서 SIMD 병렬성을 추출하는 시도를 하고 있지만, 안정적인 방법은 GCC 같은 컴파일러에서 지원하는 특수 벡터 데이터형을 사용하는거다.
* **여기서 잠깐** *SIMD(Single Instruction Multiple Data)* 란?
    * 한개의 인스트럭션으로 여러개의 데이터를 처리(연산)한다.
# 9.3 컴퓨터 시스템에서 추상화의 중요성
추상화의 사용은 전산학에서 가장 중요한 개념이다.

좋은 프로그래밍 연습의 한 가지 측면은 함수들을 간단한 응용프로그램 인터페이스 API 로 정형화하는 것으로, 프로그래머가 그 내부의 동작을 고려하지 않으면서 코드를 사용할 수 있도록 해준다.

컴퓨터 시스템의 여러 추상화
```
    Virtual machine
            Processes
                    Virtual memory  
    Instruction set              files
OS | Processor | Main Memory | I/O devices
```
프로세서 측면에서는 인스트럭션 집합 구조는 실제 프로세서 하드웨어의 추상화를 제공한다.

실제 하드웨어는 더 정교해서 여러 개의 인스트럭션을 병렬로, 그러나 항상 간단한 순차적인 모델에 의거한 방식으로 실행한다.

동일한 실행모델을 유지하기 때문에 다른 프로세서에 구현될 때도 다양한 범위의 비용과 성능을 나타내지만, 동일한 기계어 코드를 실행할 수 있다.

다양한 세 가지의 추상화를 소개했다.
* 파일을 입출력 장치의 추상화
* 가상메모리는 프로그램 메모리의 추상화
* 프로세스는 실행 중인 프로그램의 추상화

이들 추상화에 추가로 한 가지를 더하면, *가상머신*이 있다.

가상머신은 운영체제, 프로세서, 프로그램 모두를 포함하는 컴퍼튜 전체의 추상화를 제공한다.

가상머신의 개념은 1960 년대 IBM 에 의해 소개되었는데, 여러 종류의 운영체제나 동일한 운영체제의 다른 버전에서 프로그램을 실행할 수 있도록 해야 하는 컴퓨터들을 관리하는 방법으로 더욱 두드러지게 나타나고 있다.
# 10 요약
컴퓨터 시스템은 응용프로그램을 실행하기 위해 함께 동작하는 하드웨어와 시스템 소프트웨어로 구성된다.

컴퓨터 내의 정보는 상황에 따라 다르게 해석되는 비트들의 그룹으로 표시된다.

프로그램은 ASCII 문자로 시작해서 컴파일러와 링커에 의해 바이너리 실행파일로 번역되는 방식으로, 다른 프로그램들에 의해 달느 형태로 번역된다.

프로세서는 메인 메모리에 저장된 바이너리 인스트럭션을 읽고 해석함

컴퓨터가 대부분의 시간을 메모리, I/O Device, CPU Register 간에 데이터를 복사하는 데 쓴다.

계층 구조는
1. CPU Register
2. Hardware cache memory
3. DRAM Main memory
4. disk

가격은 내림차순, 용량은 오름차순

i 번째 저장장치는 i + 1 의 캐시 역할을 수행한다.

운영체제 커널은 응용프로그램과 하드웨어 사이에서 중간자 역할을 수행한다.

운영체제는 근본적인 세 가지 추상화를 제공한다.
1. 파일 (입출력 장치의 추상화)
2. 가상메모리 (메인 메모리와 디스크의 추상화)
3. 프로세스 (프로세서, 메인 메모리, 입출력 장치의 추상화)

네트워크는 시스템의 관점으로 볼 때, I/O Device 다.