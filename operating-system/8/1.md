# 8.1 Memory Management
## Logical vs Physical Address
### Logical address (=virtual address)
* 프로세스마다 독립적으로 가지는 주소 공간
* 각 프로세스마다 0번지부터 시작
* CPU가 보는 주소는 Logical Address 다.
### Physical address
* 메모리에 실제 올라가는 위치 (하드웨어)
## 주소 바인딩
* 주소를 결정하는 것
* Symbolic Address -> Logical Address -> Physical address
   * Symbolic Address = variable (컴파일 과정에서 주소가 만들어지고 이것이 물리적 메모리와 매핑이 된다. (주소 바인딩))
   * Logical Address = Virtual Address

```
Add A, B
```
* A += B 랑 같은 코드다. (A, B 는 Symbolic Address)
### Compile time binding
```
0: Add 20, 30
10: Jump 40
20: 100
30: 330
40: exit
```
* 컴파일 시에 이뤄진다.
  * 메모리 주소를 변경하고 싶으면 다시 컴파일
* 주소값을 변경 못한다.
* absolute code 라고 한다. (변경 불가능)
* Logical Address (0, 10, 20, 30, 40) 다.
* Instruction code 인거 같다.
### Load time binding
```
500 Add 20, 30
510 Jump ~
520 ~
530 ~
```
* 실행 로드시 된다.
* 앞의 숫자는 Physical Memory
* 컴파일러가 (컴파일 하고) 재배치 가능한 코드라고 해서 Relocatable code 라고 한다.
* 물리적 주소는 Base Address + Logical Address
### Run time binding
```
300 Add 20, 30
310 Jump 40
320 100
330 330
```
에서
```
700
...
```
로 변경될 수 있다.
* 숫자는 Physical Memory
* 현재 컴퓨터들이 지원하고 있는 바인딩
* 프로그램이 실행중에 주소가 변경 가능
* CPU 가 주소 참조할 때 마다 binding 상태 점검해야 됨 (MMU 라는 하드웨어가 해줌) (Memory Management Unit)
* 비어있는 부분에 계속 저장
### Dynamic Relocation
* 순서
  * CPU -> MMU -> Physical memmory
  * CPU 가 logical address 에 있는 값을 달라한다. (to MMU)
  * MMU 가 연산해서 반환
* MMU
  * relocation register(base register), limit register 를 사용해 주소 변환
### Hardware Support for Address Translation
* MMU 에서 limit register 를 이용해 값을 체크한다.
### MMU
* logical address 를 physical address 로 매핑해 준다.
* MMU scheme
  * 사용자 프로세스가 CPU 에서 수행되며 생성해내는 모든 주소값에 대해 base register 를 더해줌
* user program
  * logical address 만 사용
  * physical address 는 볼 수 없고, 알 필요도 없다.
### Dynamic Loading
프로세스 전체를 메모리에 미리 다 올리는것이 아니라 해당 루틴이 불려질 때 load 함
* memory utilization 의 향상
* 가끔씩 사용되는 많은 양의 코드의 경우 유용
  * ex ) 오류 처리 루틴
* 운영체제의 특별한 지원 없이 프로그램 자체에서 구현 가능 (프로그래머가 구현)
  * OS 는 라이브러리를 통해 지원 가능
  * 프로그래머는 OS 의 라이브러리를 사용한다.
* Loading : 메모리로 올리는 것
### Overlays
* 메모리에 프로세스의 부분 중 실제 필요한 정보만을 올림
* 프로세스의 크기가 메모리보다 클 때 유용
* 운영체제의 지원없이 사용자에 의해 구현
* 작은 공간의 메모리를 사용하던 초창기 시스템에서 수작업으로 프로그래머가 구현
  * Manual Overlay (프로그래머가 수작업 구현 (운영체제의 라이브러리 지원이 없음))
  * 프로그래밍이 매우 복잡
### Swapping
* 프로세스를 일시적으로 메모리에서 backing store 로 쫓아내는 것
* Backing store(= swap area (ex ) 하드디스크)
  * 디스크
    * 많은 사용자의 프로세스 이미지를 담을 만큼 충분히 빠르고 큰 저장 공간
* Swap in / Swap out
  * 일반적으로 중기 스케줄러(swapper)에 의해 swap out 시킬 프로세스 선정
  * priority-based CPU scheduling algorithm
    * 우선순위가 낮은 프로세스를 swapped out
    * 우선순위가 높은 프로세스를 메모리에 올림
  * Runtime binding 이 지원돼야 좋다.
    * Compile time 혹은 load time binding 에서는 원래 메모리 위치로 swap in 해야됨
  * swap time 은 대부분 transfer time(swap 되는 양에 비례함 시간) 임
### Dynamic Linking
* Static linking
  * 라이브러리가 프로그램의 실행 팡리 코드에 포함됨
  * 실행 파일의 크기가 커짐
  * 동일한 라이브러리를 각각의 프로세스가 메모리에 올리므로 메모리 낭비 (ex ) printf)
* Dynamic linking
  * 라이브러리가 실행(ex ) printf)시 link 됨
  * 라이브러리 호출 부분에 라이브러리 루틴의 위치를 찾기 위한 stub이라는 작은 코드를 둠
  * 라이브러리가 이미 메모리에 있으면 그 루틴의 주소로 가고 없으면 디스크에서 읽어옴
  * 운영체제의 도움 필요
### Allocation of Physical Memory
* 메모리는 일반적으로 두 영역으로 나뉘어 사용
  * OS 상주 영역
    * interrupt vector 와 함께 낮은 주소 영역 사용
  * 사용자 프로세스 영역
    * 높은 주소 영역 사용
    * 할당 방법
      * Contiguous allocation (연속 할당)
        * Fixed partition allocation (고정 분할 방식)
          * 미리 partition 으로 나눠놓는다.
          * 나눠놓은 영역에 프로그램을 넣는다.
            * 프로그램보다 영역이 작으면 외부 조각 (더 필요함)
            * 프로그램보다 영역이 크면 내부 조각 (남음)
            * 융통성이 없다.
          * Internal & External fragmentation 발생 (내부 조각, 외부 조각 생김)
          * 분할된 영역당 하나의 프로그램
        * Variable partition (가변 분할 방식)
          * 미리 partition 을 나누지 않는다.
          * 프로그램의 크기 고려해서 할당
          * 분할의 크기, 개수가 동적으로 변함
          * 기술적 관리 기법 필요
          * External fragmentation (외부 조각)
        * Hole
          * 가용 메모리 공간
          * 다양한 크기의 hole 들이 메모리 여러 곳에 흩어져 있음
          * 프로세스가 도착하면 수용가능한 hole 을 할당
          * 운영체제는 다음의 정보를 유지
            * 할당 공간
            * 가용 공간(hole)
        * Dynamic Storage-Allocation Problem : 가변 분할 방식에서 size n 인 요청을 만족하는 가장 적절한 hole 찾는 문제
          * First-fit
            * Size 가 n 이상인 것 중 최초로 찾아지는 hole
          * Best-fit
            * Size 와 가장 근접한 hole (오름차순)
            * Hole 들의 리스트가 크기순으로 정렬되지 않은경우 모두 탐색
            * 많은 수의 아주 작은 hole 들이 생김
          * Worst-fit
            * 가장 큰 hole 에 할당
            * 모든 리스트 탐색 (정렬 안돼있으면)
            * 상대적으로 아주 큰 hole 이 생성됨 (많이 남아서)
          * First-fit 과 best-fit 이 worst-fit 보다 속도와 공간 이용률 측먼에셔 효과적 (당연하다.)
        * Compaction
          * external fragmentation 문제를 해결하는 방법
          * hole 들을 한 군데로 모아서 큰 block 을 만듬
          * 비용이 많이 든다. (메모리를 이동해야돼서 모든 프로세스 이동)
          * 최소한의 메모리 이동으로 compaction 하는 방법 (매우 복잡하다.)
          * Compaction 은 프로세스의 주소가 실행 시간에 동적으로 재배치 가능한 경우만 가능
      * Noncontiguous allocation (불연속 할당)
        * Paging
          * 메모리 주소 공간을 같은 크기의 페이즈로 자른다. (물리적인 공간 = page frame)
          * page frame 이 존재해서 hole 들이 없어질 수 있다.
          * 주소 공간 계산이 복잡하다. (base address + page + local address)?
        * Segmentation
          * 프로그램의 주소 공간을 의미 있는 단위로 자른다.
          * code, stack, data
        * Paged Segmentation
          * Segemantation 한 후 Paging 함